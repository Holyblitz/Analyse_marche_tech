from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.firefox.options import Options
from selenium.common.exceptions import NoSuchElementException
import time
import pandas as pd

def init_driver():
    options = Options()
    # options.add_argument("--headless")
    driver = webdriver.Firefox(options=options)
    return driver

def scrape_wttj(query="data analyst", pages=3):
    offres = []
    driver = init_driver()

    for page in range(1, pages + 1):
        url = f"https://www.welcometothejungle.com/fr/jobs?query={query}&page={page}"
        driver.get(url)
        print(f"Chargement page {page} pour {query}...")
        time.sleep(5)

        if page == 1:
            try:
                cookie_button = driver.find_element(By.ID, "didomi-notice-agree-button")
                cookie_button.click()
                time.sleep(2)
            except:
                pass

        job_cards = driver.find_elements(By.XPATH, '//ul/li/div/div/div')

        for card in job_cards:
            try:
                titre = card.find_element(By.XPATH, ".//h4/div").text
            except:
                titre = "N/A"

            try:
                entreprise = card.find_element(By.XPATH, ".//span").text
            except:
                entreprise = "N/A"

            try:
                localisation = card.find_element(By.XPATH, ".//p/span/span").text
            except:
                localisation = "N/A"

            try:
                link_element = card.find_element(By.XPATH, ".//a[contains(@href, '/fr/companies/')]")
                href = link_element.get_attribute("href")

                driver.execute_script("window.open(arguments[0]);", href)
                driver.switch_to.window(driver.window_handles[1])
                time.sleep(3)

                try:
                    bouton_plus = driver.find_element(By.XPATH, '//button[contains(text(), "Afficher plus")]')
                    bouton_plus.click()
                    time.sleep(1)
                except NoSuchElementException:
                    pass

                try:
                    bloc_competences = driver.find_element(By.XPATH, '//*[@id="app"]/div/div/div/div/div[3]/section/div[1]/div[2]/div[3]')
                    competences = bloc_competences.text
                except NoSuchElementException:
                    competences = "N/A"

                driver.close()
                driver.switch_to.window(driver.window_handles[0])

            except Exception as e:
                competences = "N/A"
                print(f"Erreur acc√®s fiche : {e}")

            offres.append({
                "titre": titre,
                "entreprise": entreprise,
                "localisation": localisation,
                "competences": competences
            })

    driver.quit()
    return offres

if __name__ == "__main__":
    metiers = [
        "Programmation",
        "D√©veloppeur Web",
        "Data Scientist",
        "Cybers√©curit√©",
        "Intelligence Artificielle",
        "Data Engineer",
        "Technicien R√©seau",
        "D√©veloppeur Mobile",
        "Sp√©cialiste Base de Donn√©es",
        "Tech Lead",
        "DevOps",
        "UI Designer"
    ]

    for query in metiers:
        print(f"\nüîç Lancement scraping pour : {query}")
        results = scrape_wttj(query=query)

        for r in results:
            print(r)

        df = pd.DataFrame(results)
        nom_fichier = f"offres_{query.replace(' ', '_')}.csv"
        df.to_csv(nom_fichier, index=False)
        print(f"‚úÖ Sauvegard√© dans : {nom_fichier}")
